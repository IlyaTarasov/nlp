{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3eb71280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "aaaae4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cb824063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(url, sentiment):\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    response = session.get(url, headers=headers)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    reviews = soup.find_all('span', {'itemprop': 'reviewBody'})\n",
    "    for review in reviews:\n",
    "        rev.append(review.text)\n",
    "        sent.append(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744937c",
   "metadata": {},
   "source": [
    "##### Я буду скачивать данные с 6 разных страничек, по 15 на каждой, поэтому, сложил их разную часть ссылки в словарик с типом отзывов на данной странице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "127bb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# список для отзывов\n",
    "rev = []\n",
    "# список для тональностей отзывов\n",
    "sent = []\n",
    "dict_urls = {\n",
    "    \"?page=3&sort=negative\": 'neg',\n",
    "    \"?page=4&sort=negative\": 'neg',\n",
    "    \"?page=5&sort=negative\": 'neg',\n",
    "    \"?page=3&sort=positive\": 'pos',\n",
    "    \"?page=4&sort=positive\": 'pos',\n",
    "    \"?page=5&sort=positive\": 'pos'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f9cefcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_urls.items():\n",
    "    #соединяем инвариантную и вариативную часть ссылки\n",
    "    full_url = 'https://vseotzyvy.ru/item/547/reviews-igra-world-of-tanks/' + key\n",
    "    #закидываем в парсер ссылку и тип отзывов на ней\n",
    "    parser(full_url, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6735eeb",
   "metadata": {},
   "source": [
    "#### Токенизация, нижний регистр, лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "63524084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "for i in range(len(rev)):\n",
    "    words = [w.lower() for w in word_tokenize(rev[i]) if w.isalpha()]\n",
    "    list_of_lemmas = []\n",
    "    for word in words:\n",
    "        ana = morph.parse(word)\n",
    "        first = ana[0]\n",
    "        lemma = first.normal_form\n",
    "        list_of_lemmas.append(lemma)\n",
    "    rev[i] = list_of_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23fa50",
   "metadata": {},
   "source": [
    "#### Разбиваю на трейн и тест, как при обучении модели (чтобы потом посчитать accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "29b0b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(rev, sent, test_size=0.111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "ed6bcbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# частотные словари\n",
    "dict_pos = {}\n",
    "dict_neg = {}\n",
    "# множества для слов из только негативных и только положительных отзывов\n",
    "final_set_pos = set()\n",
    "final_set_neg = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674da140",
   "metadata": {},
   "source": [
    "#### Создаю частотные словари для лемм в положительных и негативных отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a50c7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    if y_train[i] == 'pos':\n",
    "        for token in X_train[i]:\n",
    "            if token not in dict_pos.keys():\n",
    "                dict_pos[token] = 1\n",
    "            else:\n",
    "                dict_pos[token] += 1\n",
    "    else:\n",
    "        for token in X_train[i]:\n",
    "            if token not in dict_neg.keys():\n",
    "                dict_neg[token] = 1\n",
    "            else:\n",
    "                dict_neg[token] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0015a",
   "metadata": {},
   "source": [
    "#### Если проверять, больше ли 2 слов в частотном словаре, то точность обычно ниже, а в множествах оказывается довольно мало слов, поэтому выбрасывается только самый мусор, а от 2 уже пробуем учитывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f5dd457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_pos.keys():\n",
    "    if dict_pos[key] > 1 and key not in dict_neg.keys():\n",
    "        final_set_pos.add(key)\n",
    "\n",
    "for key in dict_neg.keys():\n",
    "    if dict_neg[key] > 1 and key not in dict_pos.keys():\n",
    "        final_set_neg.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0563f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff345f3",
   "metadata": {},
   "source": [
    "#### Определяем тональность отзывов из трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "bf90480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in X_test:\n",
    "    # Создаем счетчик: каждое \"положительное\" слово +1, \"негативное\" -1\n",
    "    counter = 0\n",
    "    for token in text:\n",
    "        if token in final_set_pos:\n",
    "            counter += 1\n",
    "        elif token in final_set_neg:\n",
    "            counter -= 1\n",
    "    #Теперь по итоговой сумме видно, было больше \"положительных\" или \"негативных\" слов\n",
    "    if counter > 0:\n",
    "        y_pred.append('pos')\n",
    "    elif counter < 0:\n",
    "        y_pred.append('neg')\n",
    "    #При ничьей, наверное, не стоит решать наобум, хотя так может быть резлуьтативней, введем нейтральую тональность\n",
    "    else:\n",
    "        y_pred.append('neut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "599f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "#вообще точность варьируется от 0,5 до 1 без улучшений (в зависимости от тестовой выборки)\n",
    "#кажется, 7 выглядит как +- среднее"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687eb7ae",
   "metadata": {},
   "source": [
    "### Хочу написать небольшой комментарий. Я немного смотрел отзывы, и было некоторое количество, где отзыв явно негативный, а оценка, видимо по ошибке, стоит положительная. Чисто человеческий фактор, получается. По идее, это должно создавать некоторые проблемы, например, во множество негативных слов попадет меньше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a616f16",
   "metadata": {},
   "source": [
    "## способ улучшить алгоритм№1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fbfd03",
   "metadata": {},
   "source": [
    "#### Если слово используется 1 раз в негативных отзывах, но, допустим, 60 в положительных, то, кажется, вполне обоснованно можно посчитать его \"положительным\". Мне кажется достаточным, чтобы слово встречалось хотя бы в 4 раза чаще в одной из тональностей (на разных тестовых разные параметры дают разные результаты, в принципе может быть полезно и еще меньшее отношение), но этот параметр можно менять и смотреть как меняется результат (на 10 тестовых примерах сейчас такое особенно не оценить). Немного изменим функцию раскидывающую слова по положительным и негативным множествам. Особенно здорово это должно нивелировать нюанс что я описал в комментарии выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2f2592b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_pos.keys():\n",
    "    if dict_pos[key] > 1:\n",
    "        if key in dict_neg.keys():\n",
    "            if dict_pos[key] > 4 * dict_neg[key]:\n",
    "                final_set_pos.add(key)\n",
    "        else:\n",
    "            final_set_pos.add(key)\n",
    "\n",
    "for key in dict_neg.keys():\n",
    "    if dict_neg[key] > 1:\n",
    "        if key in dict_pos.keys():\n",
    "            if dict_neg[key] > 4 * dict_pos[key]:\n",
    "                final_set_neg.add(key)\n",
    "        else:\n",
    "            final_set_neg.add(key)\n",
    "            \n",
    "#в среднем так немного увеличивается точность +- на 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a296f0",
   "metadata": {},
   "source": [
    "## способ улучшить алгоритм№2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71dda61",
   "metadata": {},
   "source": [
    "#### Если считать точность так, что каждый верный ответ с точки зрения бинарной классификации прибавляет балл, каждый неправильный отнимает балл, а нейтральный ответ (определение тональности как нейтральной) не снимает и не добавляет, тогда ввод нейтральной тональности становится очень важным, ведь если у модели мало уверенности, то лучше воздержаться от предсказания, а не предсказывать с высоким шансом ошибки. Кажется так считать точность супер обоснованно, ведь получать противположное определение тональности нам совсем не хочется ни в каких задачах. Тогда для каждого комментария можно вести учет \"положительных\" и \"негативных\" слов, и, если разница между ними не слишком большая, тогда определять тональность нейтрально. Перепишем эту часть кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c50173ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in X_test:\n",
    "    # Создаем счетчики для положительных и негативынх слов\n",
    "    pos_counter = 0\n",
    "    neg_counter = 0\n",
    "    for token in text:\n",
    "        if token in final_set_pos:\n",
    "            pos_counter += 1\n",
    "        elif token in final_set_neg:\n",
    "            neg_counter += 1\n",
    "    #опять же параметры можно менять, добиавясь оптимальных\n",
    "    if pos_counter > 1 and pos_counter > 1.5 * neg_counter:\n",
    "        y_pred.append('pos')\n",
    "    elif neg_counter > 1 and neg_counter > 1.5 * pos_counter:\n",
    "        y_pred.append('neg')\n",
    "    else:\n",
    "        y_pred.append('neut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "a208776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        #т.к. примеров всего 10\n",
    "        accuracy += 0.1\n",
    "    elif (y_pred[i] == 'pos' and y_test[i] == 'neg'):\n",
    "        accuracy -= 0.1\n",
    "    elif (y_pred[i] == 'neg' and y_test[i] == 'pos'):\n",
    "        accuracy -= 0.1\n",
    "        \n",
    "#это более жесткий способ считать точность, тем не менее результаты +- такие же"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
